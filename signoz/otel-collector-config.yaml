connectors:
  signozmeter:
    metrics_flush_interval: 1h
    dimensions:
      - name: service.name
      - name: deployment.environment
      - name: host.name
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  # Syslog receiver for rsyslog forwarding
  syslog:
    tcp:
      listen_address: "0.0.0.0:5140"
    protocol: rfc3164
    location: America/Chicago
  # Prometheus remote write receiver for standalone Prometheus instances
  prometheusremotewrite:
    endpoint: 0.0.0.0:9090
  prometheus:
    config:
      global:
        scrape_interval: 60s
      scrape_configs:
        - job_name: otel-collector
          static_configs:
          - targets:
              - localhost:8888
            labels:
              job_name: otel-collector
        # SNMP metrics now handled by standalone Prometheus (fl-prometheus-snmp)
        # which remote-writes to SigNoz OTel collector at :4318/v1/metrics
processors:
  batch:
    send_batch_size: 10000
    send_batch_max_size: 11000
    timeout: 10s
  batch/meter:
    send_batch_max_size: 25000
    send_batch_size: 20000
    timeout: 1s
  resourcedetection:
    # Using OTEL_RESOURCE_ATTRIBUTES envvar, env detector adds custom labels.
    detectors: [env, system]
    timeout: 2s
  # Extract syslog attributes to resource attributes for fast filters
  transform/syslog:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          # Map known IPs in hostname field to proper names
          - set(attributes["hostname"], "ntopng") where attributes["hostname"] == "192.168.1.5"
          - set(attributes["hostname"], "switch.mcducklabs.com") where attributes["hostname"] == "192.168.1.2"
          # Map date hostnames by checking message for IP (for devices with bad syslog format)
          - set(attributes["hostname"], "switch.mcducklabs.com") where IsMatch(attributes["hostname"], "^\\d{4}-\\d{2}-\\d{2}$") and IsMatch(attributes["message"], "192.168.1.2")
          - set(attributes["hostname"], "ntopng") where IsMatch(attributes["hostname"], "^\\d{4}-\\d{2}-\\d{2}$") and IsMatch(attributes["message"], "192.168.1.5")
          # Filter out any remaining date hostnames (set to nil so they don't pollute)
          - set(attributes["hostname"], nil) where IsMatch(attributes["hostname"], "^\\d{4}-\\d{2}-\\d{2}$")
          # Copy hostname and appname from attributes to resource (only if valid)
          - set(resource.attributes["host.name"], attributes["hostname"]) where attributes["hostname"] != nil
          - set(resource.attributes["service.name"], attributes["appname"]) where attributes["appname"] != nil
  # Filter out noisy/repetitive logs to reduce storage
  filter/noise_reduction:
    error_mode: ignore
    logs:
      log_record:
        # Drop verbose debug logs (keep warnings and above)
        - severity_number < SEVERITY_NUMBER_INFO and resource.attributes["device.type"] != "firewall"
        # Drop repetitive DHCP requests (keep security-relevant logs)
        - IsMatch(body, "DHCPACK|DHCPREQUEST") and resource.attributes["service.name"] == "dhcpd"
        # Drop routine health checks and keepalives
        - IsMatch(body, "health check|keepalive|heartbeat") and severity_number < SEVERITY_NUMBER_WARN
        # AGGRESSIVE: Drop most ntopng logs (keep only WARN and above)
        - resource.attributes["host.name"] == "ntopng" and severity_number < SEVERITY_NUMBER_WARN
        # Drop specific ntopng noise patterns
        # CRITICAL SECURITY ALERTS RESTORED: DNS Data Exfiltration, Suspicious File Transfer
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "HTTP Susp. User-Agent")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "Susp. Device Protocol")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "Dropped Alerts")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "TLS Certificate Mismatch")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "Unresponsive Server")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "Too Many Flows")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "IoT")
        - resource.attributes["host.name"] == "ntopng" and IsMatch(body, "Empty or missing")
  # Add device context and environment tags
  transform/device_context:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          # Tag device type based on hostname patterns
          - set(resource.attributes["device.type"], "firewall") where IsMatch(resource.attributes["host.name"], "firewall")
          - set(resource.attributes["device.type"], "hypervisor") where IsMatch(resource.attributes["host.name"], "pve")
          - set(resource.attributes["device.type"], "nas") where IsMatch(resource.attributes["host.name"], "(?i)qnap|nas")
          - set(resource.attributes["device.type"], "switch") where IsMatch(resource.attributes["host.name"], "switch")
          - set(resource.attributes["device.type"], "access-point") where IsMatch(resource.attributes["host.name"], "(?i)unifi|ap")
          - set(resource.attributes["device.type"], "home-automation") where IsMatch(resource.attributes["host.name"], "(?i)^ha$|home.?assistant")
          - set(resource.attributes["device.type"], "server") where resource.attributes["device.type"] == nil
          # Environment tagging
          - set(resource.attributes["deployment.environment"], "production")
          # Network zone based on hostname or interface
          - set(attributes["network.zone"], "edge") where resource.attributes["device.type"] == "firewall"
          - set(attributes["network.zone"], "core") where resource.attributes["device.type"] == "switch"
          - set(attributes["network.zone"], "compute") where resource.attributes["device.type"] == "hypervisor"
          - set(attributes["network.zone"], "storage") where resource.attributes["device.type"] == "nas"
          - set(attributes["network.zone"], "automation") where resource.attributes["device.type"] == "home-automation"
  # Parse pfSense filterlog CSV format into structured attributes
  transform/pfsense:
    error_mode: ignore
    log_statements:
      - context: log
        statements:
          # Only process filterlog entries
          - set(attributes["pfsense.raw"], body) where resource.attributes["service.name"] == "filterlog"
          # Split CSV and extract fields (filterlog format)
          # Field positions: 0=rule,1=subrule,2=anchor,3=tracker,4=interface,5=reason,6=action,7=direction,8=ipver,...,15=proto_num,16=proto_name,17=length,18=src_ip,19=dst_ip
          - set(attributes["pfsense.interface"], Split(body, ",")[4]) where resource.attributes["service.name"] == "filterlog"
          - set(attributes["pfsense.action"], Split(body, ",")[6]) where resource.attributes["service.name"] == "filterlog"
          - set(attributes["pfsense.direction"], Split(body, ",")[7]) where resource.attributes["service.name"] == "filterlog"
          - set(attributes["pfsense.protocol"], Split(body, ",")[16]) where resource.attributes["service.name"] == "filterlog"
          - set(attributes["pfsense.src_ip"], Split(body, ",")[18]) where resource.attributes["service.name"] == "filterlog"
          - set(attributes["pfsense.dst_ip"], Split(body, ",")[19]) where resource.attributes["service.name"] == "filterlog"
          # Extract ports for TCP/UDP (field 20 and 21)
          - set(attributes["pfsense.src_port"], Split(body, ",")[20]) where resource.attributes["service.name"] == "filterlog" and (attributes["pfsense.protocol"] == "tcp" or attributes["pfsense.protocol"] == "udp")
          - set(attributes["pfsense.dst_port"], Split(body, ",")[21]) where resource.attributes["service.name"] == "filterlog" and (attributes["pfsense.protocol"] == "tcp" or attributes["pfsense.protocol"] == "udp")
          # Tag VLAN/network zone from interface name
          - set(attributes["network.vlan"], "trusted") where IsMatch(attributes["pfsense.interface"], "mvneta0.2")
          - set(attributes["network.vlan"], "iot") where IsMatch(attributes["pfsense.interface"], "mvneta0.3")
          - set(attributes["network.vlan"], "guest") where IsMatch(attributes["pfsense.interface"], "mvneta0.4")
  signozspanmetrics/delta:
    metrics_exporter: signozclickhousemetrics
    metrics_flush_interval: 60s
    latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 50ms, 100ms, 250ms, 500ms, 1000ms, 1400ms, 2000ms, 5s, 10s, 20s, 40s, 60s ]
    dimensions_cache_size: 100000
    aggregation_temporality: AGGREGATION_TEMPORALITY_DELTA
    enable_exp_histogram: true
    dimensions:
      - name: service.namespace
        default: default
      - name: deployment.environment
        default: default
      # This is added to ensure the uniqueness of the timeseries
      # Otherwise, identical timeseries produced by multiple replicas of
      # collectors result in incorrect APM metrics
      - name: signoz.collector.id
      - name: service.version
      - name: browser.platform
      - name: browser.mobile
      - name: k8s.cluster.name
      - name: k8s.node.name
      - name: k8s.namespace.name
      - name: host.name
      - name: host.type
      - name: container.name
extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  pprof:
    endpoint: 0.0.0.0:1777
exporters:
  clickhousetraces:
    datasource: tcp://clickhouse:9000/signoz_traces
    low_cardinal_exception_grouping: ${env:LOW_CARDINAL_EXCEPTION_GROUPING}
    use_new_schema: true
  signozclickhousemetrics:
    dsn: tcp://clickhouse:9000/signoz_metrics
  clickhouselogsexporter:
    dsn: tcp://clickhouse:9000/signoz_logs
    timeout: 10s
    use_new_schema: true
  signozclickhousemeter:
    dsn: tcp://clickhouse:9000/signoz_meter
    timeout: 45s
    sending_queue:
      enabled: false
service:
  telemetry:
    logs:
      encoding: json
  extensions:
    - health_check
    - pprof
  pipelines:
    traces:
      receivers: [otlp]
      processors: [signozspanmetrics/delta, batch]
      exporters: [clickhousetraces, signozmeter]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [signozclickhousemetrics, signozmeter]
    metrics/prometheus:
      receivers: [prometheus, prometheusremotewrite]
      processors: [batch]
      exporters: [signozclickhousemetrics, signozmeter]
    logs:
      receivers: [otlp, syslog]
      processors: [transform/syslog, filter/noise_reduction, transform/device_context, transform/pfsense, batch]
      exporters: [clickhouselogsexporter, signozmeter]
    metrics/meter:
      receivers: [signozmeter]
      processors: [batch/meter]
      exporters: [signozclickhousemeter]
